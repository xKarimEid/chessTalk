This repo does the following:

    1) Implement a basic tokenizer
    2) Implement GPT2
    3) Train on chess data

After this is accomplished, another repo will use default tokenizer and pretrained network
train on the same data and compare it

After that is completed

Time to do the LLM integration with a chess API

1) Wrap the encoder with fastapi
2) Add tests
3) Make a docker file
